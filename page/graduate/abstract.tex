\cleardoublepage
\chapternonum{摘要}
随着机器学习的广泛应用，其隐私保护问题也越来越突出，因此许多\textbf{隐私保护机器学习方法}被提出，旨在保护数据隐私和模型隐私的同时，实现机器学习模型的高效推断和训练。
%
当前的隐私保护机器学习方法主要分为基于密码学的方法和拆分学习两类。
基于密码学的方法拥有较高的安全性，但是其计算量和通信量较高，运行时间长，导致了实际应用中的效率问题。
拆分学习仅需交换模型计算的中间结果，无需复杂的加解密运算，因此效率相对密码学方法较高，但是相比于中心化训练依然存在较高的通信开销。
同时，在拆分学习过程中，部分模型以及模型中间结果的暴露也会带来多种隐私泄漏问题。
%

上述效率和隐私问题对隐私保护机器学习的实际应用带来了重大的挑战。
%
因此，本文围绕着隐私保护机器学习中的效率和隐私问题，进行了全面的分析研究，并且从拆分学习以及密码学和随机排列的混合方法两条路线对隐私保护机器学习中的效率和隐私问题进行优化。
%
本文的主要贡献点包括：


\textbf{（1）针对拆分学习的通信量大问题，提出了基于随机top-$k$稀疏化的通信压缩方法。}
尽管拆分学习相对于密码学方法效率较高，但是在拆分层表征尺寸大的情况下依然会带来一定的通信开销，尤其是在分类类别数目众多的情况下。
%
而当前少有研究对拆分学习的通信进行优化。
%
本文研究了稀疏、量化、拆分层缩小、L1正则化等经典的通信压缩手段，从理论上说明了在同等压缩率下稀疏化相比于缩小拆分层能够带来更大的表征空间从而提高模型泛化能力，同时展示了传统的top-$k$稀疏化会带来部分神经元难以被训练的收敛性问题。
%
基于以上分析，本文提出了随机top-$k$稀疏化方法，在提高训练和推断的通讯效率的同时，尽可能减少了模型性能的损失。

\textbf{（2）针对拆分学习面临的模型补全攻击风险，提出了基于势能损失的隐私保护方法。}
拆分学习中，样本的拆分层表征和其类别标签往往有着较高的关联性，从而导致了模型补全攻击的隐患，即：攻击者可以利用少量泄漏的样本标签或者直接对拆分层表征上进行聚类，从而得到表征到标签的映射，窃取顶部模型以及样本标签。
%
为了防御模型补全攻击，本文将攻击过程看作攻击者的有监督或无监督学习过程，从泛化误差的角度说明当样本表征分布在决策边界时，攻击效果会降低。
%
受到电磁学现象的启发，本文提出了基于势能损失函数的拆分学习隐私保护方法，通过在同类表征之间加入排斥力，使得样本表征分布在决策边界附近，相比于已有方法，显著降低了模型补全攻击的效果，同时实现最少的模型性能损失。
%

\textbf{（3）针对密码学方法非线性函数计算的性能瓶颈，提出了基于密码分享和随机排列的高效隐私保护神经网络框架。}


\textbf{（3）针对大预言模型隐私推断难题，融合优化秘密分享、随机排列和同态加密，实现秒级别的隐私推断。}



\cleardoublepage
\chapternonum{Abstract}