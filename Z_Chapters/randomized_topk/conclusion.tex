\section{本章小结}
本章节针对多分类拆分学习中的通信效率问题，提出了随机Top-$k$稀疏方法，并且从泛化误差、收敛性以及隐私性三个角度进行了理论和实验分析，证明了随机Top-$k$算法的优越性。
%
我们通过近似计算表征空间大小，表明了Top-$k$算法在同等压缩率下拥有更大的表征空间，从而使各个类别的决策区域更大，带来更低的泛化误差。
%
同时，通过一个二维例子说明了Top-$k$算法在收敛性上可能面临部分神经元无法被训练到的问题，而在Top-$k$中加入随机性可以有效地防止该类问题。
%
基于以上分析，我们提出随机Top-$k$算法对传统的Top-$k$进行了改进。
%
通过与Top-$k$算法、拆分层量化、L1正则化、缩小拆分层等方法对比，随机Top-$k$显示出了其在拆分学习训练与推断过程中的优越性，包含了更高的模型准确率和训练/推断速度。
%
此外，实验结果也表明稀疏化后的拆分层表征也能降低对于输入特征的隐私泄漏问题。
%
总之，随机Top-$k$算法显著提高了类别数量众多时拆分学习训练和推断过程中的通信效率，为拆分学习模型在实际应用中的部署提供了有力支持。
