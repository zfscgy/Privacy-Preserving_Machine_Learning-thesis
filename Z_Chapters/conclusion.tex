\chapter{总结与展望}
\section{本文工作总结}
本文深入研究了隐私保护机器学习中的效率和安全问题，针对拆分学习以及密码学和其他方法的混合方法两个方面，对隐私保护机器学习的效率和安全进行了优化，提出了一系列创新性的算法和框架。
%
这些方法在理论上有一定的创新性，同时也有较强的应用价值，可以直接部署在实际的隐私保护机器学习代码框架中。
%

在拆分学习方面，本文的研究围绕着拆分层的表征分布，创新地提出了表征的随机Top-$k$压缩方法和基于势能损失的扰动方法，分别提高了拆分学习的效率和隐私。
%
针对拆分学习的效率问题，本文探究了各种压缩方法应用于拆分学习的拆分层表征的情形，并且从表征分布空间的角度说明了Top-$k$算法在理论上有更强的泛化性能。
进一步地，我们提出随机Top-$k$算法，解决了传统的Top-$k$算法存在的收敛性问题，同时更好地发挥了理论上的泛化性优势，实现了通信高效的拆分学习训练和推理。
此外，压缩拆分层表征也能保护输入特征的隐私。
%
该方法适用于类别数量庞大、拆分层表征维度大的拆分学习模型。
%
针对拆分学习的安全问题，本文探究了拆分层表征分布和攻击效果的关系，提出将模型补全攻击视作一个有监督/无监督学习问题，将攻击效果和泛化误差联系起来。
基于此分析，本文提出了受物理学启发的势能损失函数，对拆分层表征的分布进行扰动，降低了模型补全攻击的效果，显著优于现有的降低距离相关性的方法。
该方法使得拆分层的选取可以更靠近模型输出，从而也间接地保护输入特征的隐私。

在密码学方法和其他方法的结合方面，本文首先针对密码学方法中非线性激活函数计算开销大、拟合存在误差的问题，创新性地提出了使用随机排列方法将非线性激活函数交给半可信第三方计算的方法，从而极大降低了隐私保护神经网络的计算开销。
此外，本文详细研究了随机排列和直接暴露中间结果的隐私泄露量化方法，采用距离相关性指标对隐私泄露进行了量化分析，证明了随机排列具有很强的隐私保护性能。
在此基础上，本文将随机排列方法推广至大语言模型，根据大语言模型推断过程的特性进行了优化，提高了秘密分享乘法效率；并且采用安全排列协议，将基于排列的非线性函数计算协议的在线计算由三方减少为两方，提高了安全性和通用性；此外，使用基于同态加密的隐匿查询手段来解码最终的预测单词。
%
该方法将大语言模型的隐私推断的开销降低到秒级别，效率相比于已有的密码学方法有超过百倍的提升。


\section{未来工作展望}
针对本文上述的研究工作，在隐私保护机器学习的效率和安全方面，有以下几个问题可以在未来深入研究：
%

针对拆分学习的通信压缩问题，进一步将稀疏化和量化结合起来提高通信效率，并且可以调研根据拆分层的具体结构针对性地进行压缩：如拆分层为卷积层时，更多地使用量化方法避免丢失过多信息；拆分层为全连接层时，则考虑将量化和稀疏化结合。
将通信压缩与神经网络架构搜索（Neural Architecture Search）~\cite{renpengzhen_2021_nas_survey}结合，自动化地根据具体场景找到最优压缩方案。
此外，通信压缩对拆分学习安全性的影响也值得深入研究。

针对拆分学习的安全问题，需要进一步对隐层表征的数据分布对于攻击者泛化误差的影响进行深入研究，需要考虑多分类情形，探究更加精确的量化关系。
探究新的扰动方法，如变分推断~\cite{kingma_2014_vae,alemi_2022_deep_variational}等应用于拆分学习隐层表征的效果。
研究拆分学习训练场景中的隐私保护，特别是对梯度中包含的标签信息的保护。

针对密码学和随机排列的混合方法，可以进一步对随机排列的安全性进行研究，并且结合多精度训练等方法进一步提高隐私保护神经网络的效率。
%
探究线下阶段的半可信第三方的安全性增强，如通过区块链~\cite{belotti_2019_blockchain}等技术将单一的半可信第三方转化为多个隐私服务提供方，通过共识机制（Consensus Mechanism）等方案共同保证安全性，实现更加实用的隐私保护机器学习框架。
%
探究全同态加密（Fully Homomorphic Encryption）技术与秘密分享、随机排列的结合，特别是优化线性计算部分，减少秘密分享带来的高通信量性能瓶颈，也是未来值得研究的方向。