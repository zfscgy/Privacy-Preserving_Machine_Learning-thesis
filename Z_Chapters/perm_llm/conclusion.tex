\section{本章小结}
本章我们研究了大语言模型的隐私推断问题，提出了拆分学习在此问题上的不可行性。
%
针对密码学方法的大语言模型隐私推断中非线性激活函数开销大的问题，我们基于第\ref{chap:ss-perm}章提出的隐私保护神经网络框架进行改进，并且对秘密分享进行进一步优化，结合同态加密技术，实现了高效的大模型隐私推断框架PermLLM。
%
我们利用PermLLM框架实现了ChatGLM-6B模型，在现实的网络环境下实现了秒级别的隐私推断速度，为大语言模型隐私推断的实用打下了基础。