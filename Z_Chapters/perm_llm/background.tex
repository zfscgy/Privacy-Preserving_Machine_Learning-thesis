\section{研究背景}
2023年ChatGPT的出现，标志着人工智能的发展到达了一个新的阶段~\cite{chatgpt}。
%
ChatGPT以及类似的大语言模型（Large Language Models），通过利用大量的语料进行自回归训练以及人类反馈强化学习，从而实现了与人类进行自然对话的能力，并且在大量任务上都达到了最先进水平~\cite{}。
%
通过提示词，大模型可以完成多种多样的任务，其效果往往超过此前研究者针对该任务精心设计的模型~\cite{}。
%
因此，当前大语言模型成为了学术界和业界的焦点，基于大语言模型的应用也层出不穷，包括了各种领域的问题回答（Question Answering）、阅读理解（Reading Comprehension）、文本生成（Text Generation）、检索增强（Retrieval Augmented Generation）等~\cite{}。


在大模型被广泛应用的同时，其隐私问题也愈加突出。
%
大模型的训练成本极大，据估计，一个GPT-3模型训练的计算成本已经高达数百万美金。
%
因此，大模型的模型参数是公司的重要资产，不能直接以开源的方式提供给用户。
%
在这种情况下，用户必须调用模型拥有方（如OpenAI公司）提供的接口（API）来使用大模型。
%
用户将自身的输入文本发送给模型拥有方的服务器，服务器上执行明文的大模型推断，然后将结果返还给用户。
%
在这个过程中，用户输入文本的隐私就被完全暴露给了模型拥有方。
%
这带来了极大的隐私泄漏风险。
%
例如，三星公司的员工使用ChatGPT分析了公司内部的机密数据，使得三星公司开始禁止员工使用类似的大模型工具~\cite{}。
%
因此，上述的隐私泄露风险给大语言模型的应用产生了一定程度的阻碍。


为了解决大模型的隐私问题，在应用大模型时同时保护用户输入和模型参数的隐私，一些研究基于密码学方法提出了初步的解决方案。
%
这些方法一般采用已有的秘密分享或同态加密方案来实现大模型中的线性运算，然后采用高阶多项式拟合的方式来实现大模型中的非线性运算，如GeLU、Softmax等。
%
但是由于采用密码学的隐私保护机器学习框架自身会带来巨大的额外开销，加之大模型的参数规模和运算量十分庞大，上述方法即使在理想的计算资源与网络环境下，也至少需要消耗几分钟时间、数十GB流量才能产生一个输出单词。
%
因此，基于密码学方法的大模型隐私推断框架的实用性依然欠缺，并且可以预见到使用已有的密码学底层算法很难实现具备实用性的大模型隐私推断。
%
如何在保护输入的模型隐私的基础上，实现高效安全的实现大模型推断，依然是一个亟待解决的问题。
