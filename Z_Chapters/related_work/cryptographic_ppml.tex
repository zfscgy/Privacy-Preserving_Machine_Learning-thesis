\section{基于密码学的隐私保护机器学习}
纵向联邦学习可以看作是特定的一类隐私计算问题，即：在保护数据和模型参数的情况下进行模型的训练和推断，因此也可以通过基于密码学的安全多方计算（Secure Multiparty Computation）来实现。

\begin{definition}[安全多方计算]
    有$n$个参与方$P_1, \cdots, P_n$与各自的输入$X_1, \cdots, X_n$，以及一个公共函数$f$，安全多方计算指的是各方根据指定的协议交互计算出$Y= f(X_1, \cdots, X_n)$（$Y$可以是公开的或是被指定的参与方获得，两种定义是等价的），同时保护各方输入的隐私。
\end{definition}

注意安全多方计算的定义隐含了安全性设定（Security Setting），也就是对于各个参与方行为的限制条件。
安全性设定主要可以分为两种，包括：
各个参与方忠实按照协议规则执行协议但是同时利用自己获取到的一切信息，称为半可信（Semi-honest）安全性设定；
以及参与方可能存在不遵守计算协议的情况，称为恶意（Malicious）安全性设定；
此外，也有在上述两种情况下存在部分参与方共谋（Collusion）的设定。
%
复杂的安全性设定可能导致极为复杂的协议设计和安全性证明。
%
本文遵循一般隐私保护机器学习中的半可信安全性设定~\cite{wagh2019securenn,mohassel2018aby3,riazi_2018_chameleon}。
%
%


安全多方计算协议往往基于几种特定的密码学原语来实现，包括秘密分享（Secret Sharing）、同态加密（Homomorphic Encryption）、混淆电路（Garbled Circuits）等。
%
下面对此进行简要介绍。
%


\textbf{秘密分享}：
秘密分享~\cite{shamir1979share}指的是把一个值分享给多个参与方，其中一定数量的参与方合作才能恢复出该值。
%
具体而言，
%
$(t,n)$-秘密分享指的是将一个值$x$分享给$n$方$P_0, \cdots, P_{n-1}$，其中$P_i$得到的值记作$\langle x \rangle_i$。
%
至少要$t$个参与方一起，才能恢复出$x$的值。低于$t$个参与方则无法得到任何关于$x$的信息。
%
常用的秘密分享包括两方加法分享（Additive Sharing）以及两方布尔分享（Boolean Sharing），这两种分享分别把一个数$x$拆分成两个随机数相加（$x = \langle x \rangle_0 + \langle x \rangle_1$）或是两个随机数（按位）异或（$x = \langle x \rangle_0 \oplus \langle x \rangle_1$）。
%
在秘密分享的情况下，进行加法（异或）只需各方本地运算，但是进行乘法（异与）较为复杂，一般可以采用离线（Offline）计算的Beaver三元组进行~\cite{beaver1992efficient}，即：在获得具体的输入前，两方通过一定方法计算出一组秘密分享的随机数$(u,v,w)$满足$uv = w$。
%
一般两方在离线阶段可以使用同态加密~\cite{paillier1999,gentry2009fully}、不经意传输（Oblivious Transfer）~\cite{yadav_2022_ot_survey}等手段生成Beaver三元组；
在三方场景下，可以使用一个半可信第三方生成分发从而提高效率。
%
注意秘密分享一般在有限域（Finite Domain）上进行，如：加法分享在模$N$的整数环$\mathbb Z_N$进行，布尔分享按照定义在$\mathbb Z_2$进行）。
%
此时各方所获取到的值在自身视角中都是在有限域上均匀分布的随机数，与实际值无关，因此实现信息论安全（Information-Theoretic Security）。


\textbf{同态加密}：
同态加密是一类特殊的加密算法，其支持在密文上进行一定的计算，使得解密的结果和明文计算一致。
%
令某种加密系统的加密函数为\textsf{Enc}，解密函数为\textsf{Dec}。
%
如果对于某个定义在明文上的运算符$\mathsf{OP}_P$，存在密文上的运算符$\mathsf{OP}_C$，使得对于任意明文$X, Y$都满足：
\begin{equation}
    \textsf{OP}_P(X, Y) = \mathsf{Dec}[\mathsf{OP}_C (\mathsf{Enc}[X], \mathsf{Enc}[Y])],
\end{equation}
%
则称该加密系统可以同态地计算$\mathsf{OP}_P$的运算。
%
注意$\mathsf{OP}_P$ 往往不等于 $\mathsf{OP}_C$。
比如，Paillier同态加密支持明文加法，即：$\mathsf{OP}_P=$`$+$'，但是对应的密文运算是乘法，也就是$\mathsf{OP}_C=$`$\times$'。
%
同态加密按照支持的运算的不同，一般可以分为半同态加密（Partial Homomorphic Encryption）和全同态加密（Fully Homomorphic Encryption）。
%
半同态加密支持一种同态运算，如加法或乘法，分别可以称为加同态加密和乘同态加密。
%
全同态加密同时支持加法或乘法。
%
除此之外，还有分级（Leveled）全同态加密，其只支持一定次数多乘法运算。
%
当前常用的同态加密包括Paillier加同态加密~\cite{paillier1999}，其定义域为大整数；BFV/BGV全同态加密~\cite{2012bfv1,2012bfv2,2014bgv}，其定义域为整系数多项式；以及CKKS全同态加密~\cite{ckks2017}，其定义域是实系数多项式，并且运算过程会产生一定的误差。


\textbf{混淆电路}：
混淆电路由姚期智院士于1986年提出~\cite{yao1986gc}，是一个两方安全计算协议，可以用于计算任意布尔电路。
%
混淆电路通过对原始电路的逻辑门进行“混淆”得到，具体而言，每个门的输入和输出都变成了随机数，因此无法根据混淆后的电路的输入、输出以及中间值，获取关于原始电路输入输出值的任何信息。
%
混淆电路的执行过程可以表示为：给定一个公开函数$f$，某方（这里设为$P_0$）产生一个布尔电路$C$，然后对其进行混淆得到混淆电路$C^G$，并发送给另一方（这里设为$P_1$）；同时，$P_0$自身的输入$X_0$ 混淆后得到 $X_0^G$
%
同时，$P_1$和$P_0$ 执行不经意传输协议~\cite{yadav_2022_ot_survey}，获取$P_1$输入的混淆值 $X_1^G$。
%
然后$P_1$可以根据混淆输入计算出混淆输出$Y_G = C_G(X_0^G, X_1^G)$，将其返还给$P_0$后，$P_0$根据自身维护的混淆表得到实际的输出值。
%
混淆电路只需要常数轮的通信即可计算任何门电路的值，但是因为电路中的每个布尔值都转化成了高位的随机数，会消耗大量通信流量；由于涉及密码学计算，也有较大的计算开销。
%
混淆电路发展至今有多种优化方案提出，包括Free-XOR~\cite{kolesnikov2008free_xor}，HalfGate~\cite{zahur2015halfgate}等，降低了通信和计算开销。
%

除去以上介绍的几种密码学技术，多方安全计算还可以包含其他技术，以及一些定制化的计算协议。
如不经意传输~\cite{yadav_2022_ot_survey,chou_2015_simplest_ot}可以使得一方从另一方拥有的多个值中按照下标选取一个值，同时不暴露查询的下标以及未被选择的值。
%
下文将对部分主要的基于密码学的隐私保护机器学习研究进行介绍。


\subsection{基于单一密码学技术的隐私保护机器学习}
本节对采用单一密码学技术来实现隐私保护机器学习的相关工作进行介绍。
%
这些工作基于两方的隐私保护机器学习场景，如MLaaS（Machine Learning as a Service），即：用户提供数据，服务方提供机器学习模型，两方进行训练或推断的情况。
%

\textbf{基于同态加密}：
2016年微软提出CryptoNets~\cite{gilad2016cryptonets}，率先通过同态加密实现神经网络的推断。
%
由于神经网络的权重和输入都被加密，因此这种方法可以实现安全的神经网络推断。
%
CryptoNets采用了YASHE加密算法~\cite{bos2013yashe}，这是一种分级同态加密算法，可以支持一定次数的乘法运算。
%
由于同态加密仅支持加法和乘法运算，因此CryptoNets将神经网络中的非线性激活函数替换成了平方函数，然后在明文上训练得到模型权重。
%
该方法需要花费数分钟和300Mb左右的流量对MNIST数据集中的一张图片进行分类。
%
%
一些研究~\cite{hesamifard2017cryptodl,chabanne2017pp_dnn}对CryptoNets进行了改进，包括使用更加精确的多项式拟合激活函数、将同态加密算法换为BGV~\cite{2014bgv}或CKKS~\cite{ckks2017}等更高效的算法，以及优化同态加密的密文打包技术等。
%
Zhou等人~\cite{zhoujunwei2020binary_encrypted_nn}通过将卷积神经网络的权重二值化，实现了更高效的基于全同态加密的神经网络推理。

\textbf{基于混淆电路}：
DeepSecure框架~\cite{rouhani2018deepsecure}将神经网络模型转化为布尔电路，从而实现隐私神经网络推断。
%
为了提高效率，该框架减少了各类电路中的非异或门数目，从而适配Free-XOR算法。
%
该框架运算速度高于CryptoNets，但是带来了更高的通信开销。
%
实验表明，一个简单的全连接网络的推断消耗800MB左右的流量。
%
XONN框架~\cite{riazi2019xonn}将二值神经网络（Binary Neural Network）~\cite{qinhaotong_2020_binary_nn}与混淆电路结合，将内积运算转变为异或运算，从而极大地提高了安全推断的效率。


\subsection{混合多种密码学技术的隐私保护机器学习}
为了提高隐私保护机器学习的效率，现有的隐私保护机器学习框架大多将多种密码学技术混合，为机器学习中不同的算子找到最佳的密码学技术。
%
我们在下文将主流的基于密码学的隐私保护机器学习框架按照参与方个数分别介绍。

\textbf{两方框架}：
ABY框架~\cite{demmler2015aby}提出将算术秘密分享、布尔秘密分享以及YAO分享（基于混淆电路~\cite{yao1986gc}的两方分享，一方持有混淆值和真实值的对照表，另一方持有混淆电路和混淆值）融合，并且设计协议对三种分享状态的值进行相互转化，从而为特定的计算任务找到最适合的混合计算协议。
%
SecureML框架~\cite{mohassel2017secureml}将算术秘密分享和混淆电路结合，实现了逻辑回归的推断和训练。
%
其还使用分级同态加密和不经意传输对算术秘密分享的Beaver三元组~\cite{beaver1992efficient}的离线生成进行了优化，并且将Sigmoid函数表示为分段线性函数，通过混淆电路（计算当前值落在哪一段）和算术秘密分享融合来提高计算效率。
%
MiniONN框架~\cite{liujian2017minionn}将秘密分享和混淆电路进一步应用于神经网络推断中，并且使用分段的Spline插值来拟合激活函数，以及采用SIMD（Single Instruction Multiple Data）技术加速了Beaver三元组的生成，从而提高了隐私神经网络的模型准确率和效率。
%
Gazelle框架~\cite{juvekar2018gazelle}使用优化的基于格密码的同态加密（BFV加密~\cite{2012bfv1,2012bfv2}）直接加速安全矩阵乘法计算，而非用于产生三元组，从而极大降低了通信开销；同时采用混淆电路来计算ReLU、最大池化（Max Pooling）等非线性运算。
实验结果表明Gazelle的性能甚至大幅度优于需要依赖第三方的Chameleon框架。
%
Delphi框架~\cite{mishra2020delphi}基于Gazelle框架进行了改进，将同态加密的安全乘法计算用于离线计算Beaver三元组，并利用了神经网络推断过程中权重不变的特性减少了在线的开销；同时将ReLU激活函数替换成二次函数以降低开销。
%
CryptFlow2框架~\cite{rathee2020cryptflow2}基于秘密分享，采用同态加密和不经意传输实现安全乘法，并且新设计了高效的基于不经意传输的安全比较和除法协议，将两方的隐私保护机器学习推广到ResNet~\cite{hekaiming2016resnet}等大型模型中。
%
Cheetah框架~\cite{huang2022cheetah}进一步对基于同态加密的神经网络线性运算以及基于不经意传输的ReLU激活函数等非线性运算进行优化。
%si
SIRNN框架~\cite{rathee2021sirnn}通过查真值表的方式计算指数函数，进一步对神经网络中的Softmax等非线性函数进行了优化。

\textbf{三方框架}：
Chameleon框架~\cite{riazi_2018_chameleon}混合秘密分享、GMW协议~\cite{gmw_1987}和混淆电路协议进行神经网络计算，在离线阶段使用了可信硬件~\cite{sabt_2015_tee}作为第三方，并采用相关随机性（Correlated Randomness）在各方生成相同的随机数，提高了Beaver三元组产生的效率。
%
ABY3框架~\cite{mohassel2018aby3}基于ABY框架~\cite{demmler2015aby}，将秘密分享、布尔分享和混淆电路推广到三方计算的场景以提高效率，并对乘法截断进行了改进。
%
SecureNN框架~\cite{wagh2019securenn}采用了两方秘密分享并且使用第三方来产生Beaver三元组，同时基于比较的布尔运算电路设计了高效的三方安全比较协议，实现了高效的隐私神经网络推断。
%
CryptFlow~\cite{kumar2020cryptflow}是一个支持两方和三方协议的开源框架，其两方协议采用的是ABY协议，而三方协议基于SecureNN框架，对其卷积操作的Beaver三元组进行了优化，同时使用相关随机性来进一步降低通信量；该框架还提供了基于可信执行环境（Trusted Execution Environment）~\cite{sabt_2015_tee}的恶意安全转换机制，可以将半可信安全的协议转换为恶意安全的协议。
%
Crypten框架~\cite{knott2021crypten}基于秘密分享和GMW协议~\cite{gmw_1987}实现安全的深度学习，并且提供了类似Pytorch~\cite{2019_pytorch}风格的接口，使得非密码学专业研究者也可以进行隐私保护机器学习。
%
Falcon框架~\cite{wagh2021falcon}基于ABY3和SecureNN进行了改进，优化了比较协议。
%
AriaNN框架~\cite{ryffel2021ariann}提出使用函数秘密分享（Function Secret Sharing）来计算比较函数，将其降低到仅需一轮通信轮次。

\subsection{其他相关研究}
除了设计安全多方计算框架之外，也有一些其他关于提高基于密码学的隐私保护机器学习效率的研究。
%
比如，
Dalskov等~\cite{dalskov2020secure_q8}研究了将量化（Quantization）技术应用于隐私保护机器学习，将神经网络量化到8比特，并在多个现有的隐私保护机器学习框架上进行了测试。
%
此外，也有许多对于非神经网络的专用机器学习模型进行隐私保护的研究，如树模型~\cite{wu2020vf_tree,fang2021secure_xgb,lu2023squirrel}、聚类模型~\cite{bunn2007secure_kmeans,wu2020secure_kmeans}、矩阵分解~\cite{nikolaenko2013ppmf,kim2018ppmf}等。
%
这些方法往往基于已有的同态加密、混淆电路、多方安全计算协议等技术，对于特定的机器学习模型进行设计和优化。
%


2023年起，随着ChatGPT~\cite{chatgpt}的出现，大语言模型在工业界和学术界产生了巨大的影响。
%
而大模型的参数量和计算量都极为巨大，即使是明文推断的情况下也对硬件有较高要求，因此对基于密码学的隐私保护机器学习提出了新的挑战。
%
Iron Transformer~\cite{hao2022iron}，MPCFormer~\cite{li2022mpcformer}，SecureTLM~\cite{chen2024securetlm}，PrivFormer~\cite{akimoto2023privformer}等框架在之前研究的基础上，采用同态加密、秘密分享、多项式拟合ReLU、使用特定模型结构等方法，实现了Transformer模型的隐私保护推断。
%
针对参数量高达数十亿的大语言模型，最近也有研究基于已有的ABY3协议或Cheetah框架进行~\cite{dong2023puma,lu2023bumblebee,hou2023ciphergpt}。
目前这些方案在生成单个输出单词时需要至少进行数十GB的流量传输，在理想环境下也需要数分钟的计算时间，因此依然难以用于实际应用。



