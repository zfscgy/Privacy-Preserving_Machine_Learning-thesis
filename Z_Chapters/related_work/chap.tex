\chapter{相关研究综述}
隐私保护机器学习（Privacy-Preserving Machine Learning）指的是在保护数据以及模型隐私的前提下进行机器学习模型的训练和推断。
%
当前的隐私保护机器学习包含了基于密码学的隐私计算、拆分学习、联邦学习、可信执行环境、差分隐私等多种方法。
%
基于密码学的隐私计算~\cite{al_2019_ppml}通过各种密码学底层技术实现可证明安全的隐私保护机器学习，但是由于牵涉到大量密码学计算，会带来较高的通信和计算开销。
%
拆分学习~\cite{vepakomma2018split}通过切分模型和交换中间结果实现隐私的训练和推断，具有实现简单、计算和通信开销小的优点，但是由于部分模型和中间结果的暴露，存在一定的隐私泄露风险。
%
联邦学习\cite{yangqiang2019federated,mcmahan_2017_fedavg}通过多个参与方聚合模型来保护各个参与方的本地数据隐私，适用于数据横向分割、训练阶段的场景。
%
可信执行环境~\cite{sabt_2015_tee,2016_intel_sgx}将模型和数据装载入特定可以被信任的硬件中进行运算，与外部环境隔离，从而实现隐私保护。
%
差分隐私~\cite{dwork_2006_differential_privacy,wuruihan_2023_label_dp}通过在计算过程中加入特定分布的噪声，使得计算结果满足一定的隐私性，可以控制输入数据的隐私泄露程度，但是其必须在隐私保护程度和计算精确性之间进行权衡~\cite{abadi_2016_dp_dl}。
%
上述的几类方法彼此相对独立，但是又在一定程度上相互重叠，大量研究~\cite{zhangqiao_2018_gelu_net,bonawitz_2017_secure_agg,thapa_2022_splitfed,zhou_2022_codesign,riazi_2018_chameleon,weikang_2020_fed_dp}采用其中的多种方法来共同构建新的隐私保护机器学习方法，旨在更好地平衡效率和安全。
%
本文主要研究通用的适用于多方场景的隐私保护机器学习算法框架，重点面向两方进行隐私保护的神经网络联合训练和推断的场景，因此聚焦于拆分学习、密码学方法以及密码学和非密码学的混合方法三个方面。
%
本章节对以上的三个方面的研究现状逐一进行更细致的介绍。

\input{Z_Chapters/related_work/split_learning.tex}
\input{Z_Chapters/related_work/cryptographic_ppml.tex}
\input{Z_Chapters/related_work/mixed.tex}