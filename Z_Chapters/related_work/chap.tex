\chapter{相关研究综述}
隐私保护机器学习（Privacy-Preserving Machine Learning）指的是在保护数据以及模型隐私的前提下进行机器学习模型的训练和推断~\cite{tan_2020_PPML_survey_ch}。
%
当前的隐私保护机器学习包含了基于密码学的隐私计算、拆分学习、联邦学习、可信执行环境、差分隐私等多种方法。
%
基于密码学的隐私计算~\cite{al_2019_ppml}通过各种密码学底层技术实现可证明安全的隐私保护机器学习，但是由于牵涉到大量密码学计算，会带来较高的通信和计算开销。
%
拆分学习~\cite{vepakomma2018split}通过切分模型和交换中间结果实现隐私的训练和推断，具有实现简单、计算和通信开销小的优点，但是由于部分模型和中间结果的暴露，存在一定的隐私泄露风险。
%
联邦学习\cite{yangqiang2019federated,mcmahan_2017_fedavg, zhouchuanxin_2021_fed_survey_ch}通过多个参与方聚合模型来保护各个参与方的本地数据隐私，适用于数据横向分割、训练阶段的场景。
%
可信执行环境~\cite{sabt_2015_tee,2016_intel_sgx}将模型和数据装载入特定可以被信任的硬件中进行运算，与外部环境隔离，从而实现隐私保护。
%
差分隐私~\cite{dwork_2006_differential_privacy,wuruihan_2023_label_dp}通过在计算过程中加入特定分布的噪声，使得计算结果满足一定的隐私性，可以控制输入数据的隐私泄露程度，但是其必须在隐私保护程度和计算精确性之间进行权衡~\cite{abadi_2016_dp_dl}。
%
上述的几类方法彼此相对独立，但是又在一定程度上相互重叠，大量研究~\cite{zhangqiao_2018_gelu_net,bonawitz_2017_secure_agg,thapa_2022_splitfed,zhou_2022_codesign,riazi_2018_chameleon,weikang_2020_fed_dp}采用其中的多种方法来共同构建新的隐私保护机器学习方法，旨在更好地平衡效率和安全。
%
我们将上述的各种隐私保护机器学习的研究方向归纳在\autoref{tab:related_work}中。
%
本文主要研究通用的适用于多方场景的隐私保护机器学习算法框架，重点面向两方进行隐私保护的神经网络联合训练和推断的场景，因此聚焦于拆分学习、密码学方法以及密码学和非密码学的混合方法三个方面。
%
本章节对以上的三个方面的研究现状逐一进行更细致的介绍。

\begin{table}[h]
    \small
    \label{tab:related_work}
    \caption{隐私保护机器学习相关研究概览}
    \begin{tabular}{p{45pt}p{250pt}p{22pt}cp{22pt}p{22pt}}
    \toprule
        研究方向       & 描述                                                                                       & 适用范围 & 效率 & 安全性 & 模型精度 \\ \midrule
        基于密码学的隐私计算 &
          通过密码学协议，实现安全的模型训练和推断。适用于单次计算中参与方较少（2方或3方）的场景（包括纵向联邦学习、隐私推断）。可以采取通用的协议实现不同模型的隐私计算，具有可以证明的安全性，但是存在计算的通讯开销大的缺点。 &
          较大 &
          低 &
          高 &
          高 \\ \midrule
        拆分学习       & 按照各方拥有的数据情况，将拆成多份部署在各方，各方交换中间结果完成模型的训练和推断。适用于纵向联邦学习、隐私推断等场景。实现简单，效率较高，但是会一定程度暴露数据和模型的隐私。 & 较大   & 较高  & 较低   & 高    \\ \midrule
        联邦学习（横向）   & 多方共同训练模型，然后在中心化服务器上聚合模型。适用于数据横向分割的情况（各方拥有特征列一致的样本）。只适用于数据横向分割的模型训练场景，且数据隐私存在泄漏风险。 & 较小   & 中  & 中   & 中    \\ \midrule
        可信执行环境     & 在可信硬件上执行中心化的安全计算，基于硬件保证安全性。可适用于多种场景，由于硬件所限，计算效率有一定程度的损失。                                 & 较大   & 中  & 中   & 高    \\ \midrule
        差分隐私 &
          通过在模型计算的特定环节加入精心计算的噪声，使得计算结果实现一定的差分隐私。由于其具体实现仅仅为加入噪声，因此效率损失很小。但是需要在模型精度和安全性之间进行权衡，且其实际的隐私保护程度难以计算，因为差分隐私本身定义来自于“最坏情况的隐私泄露上界”。 &
          较大 &
          高 &
          \multicolumn{2}{c}{相互权衡} \\ \midrule
        密码学和非密码学混合 & 通过损失部分安全性的情况下，对基于密码学的隐私计算协议的效率进行优化。一般可以采用与拆分学习、可信执行环境结合的方式。                              & 较大   & 中  & 中   & 高    \\ \bottomrule
        \end{tabular}
\end{table}

\input{Z_Chapters/related_work/split_learning.tex}
\input{Z_Chapters/related_work/cryptographic_ppml.tex}
\input{Z_Chapters/related_work/mixed.tex}