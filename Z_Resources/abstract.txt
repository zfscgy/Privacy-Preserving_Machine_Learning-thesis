随着机器学习的广泛应用，其隐私问题也越来越突出，因此许多隐私保护机器学习方法被提出，旨在保护数据隐私和模型隐私的同时，实现机器学习模型的高效推断和训练。隐私保护机器学习中的两种重要方法为基于密码学的隐私计算和拆分学习。基于密码学的方法拥有较高的安全性，但是其计算量和通信量较高，运行时间长，导致了实际应用中的效率低下问题。拆分学习仅需交换模型计算的中间结果，无需复杂的加解密运算，因此效率相对密码学方法较高，但是相比于中心化训练依然存在较高的通信开销。同时，在拆分学习过程中，部分模型以及模型中间结果的暴露也会带来多种隐私泄漏问题，导致其安全性受到质疑。上述效率和安全问题对隐私保护机器学习的实际应用带来了重大的挑战。因此，本文围绕着隐私保护机器学习中的效率和安全问题，进行了全面的分析研究，并且从拆分学习以及密码学和随机排列的混合方法两条路线对隐私保护机器学习中的效率和安全进行优化。本文的主要贡献点包括：（1）针对拆分学习的通信量大问题，提出了基于随机Top-k稀疏化的通信压缩方法。尽管拆分学习相对于密码学方法效率较高，但是在拆分层表征尺寸大的情况下依然会带来一定的通信开销。本文研究了稀疏、量化、拆分层缩小、L1正则化等经典的通信压缩手段，从理论上说明了在同等压缩率下稀疏化相比于缩小拆分层能够带来更大的表征空间从而提高模型泛化能力，同时展示了传统的Top-k稀疏化会带来部分神经元难以被训练的收敛性问题。基于以上分析，本文提出了随机Top-k稀疏化方法，在提高训练和推断的通信效率的同时，尽可能减少了模型性能的损失。（2）针对拆分学习面临的模型补全攻击风险，提出了基于势能损失的隐私保护方法。拆分学习中，样本的拆分层表征和其类别标签往往有着较高的关联性，从而导致了模型补全攻击的隐患，即：攻击者可以利用少量泄漏的样本标签或者直接对拆分层表征上进行聚类，从而得到表征到标签的映射，窃取顶部模型以及样本标签。为了防御模型补全攻击，本文将攻击过程看作攻击者的有监督或无监督学习过程，从泛化误差的角度说明当样本表征分布在决策边界时，攻击效果会降低。受到电荷分布现象的启发，本文提出了基于势能损失函数的拆分学习隐私保护方法，通过在同类表征之间加入排斥力，使得样本表征分布在决策边界附近，相比于已有方法，显著降低了模型补全攻击的效果，同时实现最少的模型性能损失。（3）针对密码学方法非线性函数计算的性能瓶颈，提出了基于秘密分享和随机排列的高效隐私保护神经网络框架。密码学的隐私保护神经网络框架面临着非线性激活函数开销大的问题，而另一方面，拆分学习或其他混合方法存在着中间结果泄露隐私的问题。本文基于随机排列协议，提出在半可信第三方上对随机排列的明文进行非线性逐元素函数的计算，并结合秘密分享，实现了高效的隐私保护神经网络推断与训练。此外，本文基于距离相关性指标对随机排列的安全性进行了详细的量化分析，表明了随机排列后的中间结果泄露信息可忽略不计。（4）针对大语言模型隐私推断难题，融合优化秘密分享、随机排列和同态加密，实现秒级别的隐私推断。大语言模型的参数量众多且计算量庞大，给隐私保护机器学习带来了新的挑战。本文首先证明大模型中间结果几乎完全保留了输入信息，因此传统的拆分学习方法无法应用于大语言模型。考虑到密码学方法在处理非线性函数时的高开销的问题，本文提出混合随机排列、秘密分享以及同态加密三种技术，针对大模型推断过程进行深度优化，建立高效的大模型隐私推断框架，并在开源大模型的基础上实现了秒级别的大模型隐私推断。